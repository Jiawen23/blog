

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>模型检验 &mdash; 张振虎的博客 张振虎 文档</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />

  
  

  
  

  
    <link rel="canonical" href="https://zhangzhenhu.github.io/blog/glm/source/模型评估/influence_bak.html" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/translations.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"RR": "{\\bf R}", "bold": ["{\\bf #1}", 1]}}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> 张振虎的博客
          

          
          </a>

          
            
            
              <div class="version">
                acmtiger@outlook.com
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">目录:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">广义线性模型</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html">1. 概率基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id2">1.1. 概率模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id3">1.1.1. 概率律</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id4">1.1.2. 离散模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id5">1.1.3. 连续模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id6">1.2. 条件概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id7">1.3. 联合概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id8">1.4. 全概率与贝叶斯定理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id9">1.5. 独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id10">1.6. 随机变量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id11">1.6.1. 离散随机变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id12">1.6.2. 连续随机变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id13">1.6.3. 累积分布函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id14">1.6.4. 随机变量的函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id15">1.6.5. 期望与方差</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id16">1.7. 边缘化</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id17">1.8. 常见概率分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id18">1.8.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id19">1.8.2. 二项式分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id20">1.8.3. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id21">1.8.4. 多项式分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id22">1.8.5. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#id23">1.8.6. 卡方分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#t">1.8.7. t分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/content.html#f">1.8.8. F分布</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html">2. 最大似然估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#ch-liklihood">2.1. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id3">2.2. 伯努利分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id4">2.3. 类别分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#ch-2-gaussian-ml">2.4. 高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/content.html#id6">2.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html">3. 推荐与检验</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id2">3.1. 统计量和充分统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-sample-distribution">3.2. 抽样分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-sample-distribution-normal">3.2.1. 正态分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#t">3.2.2. t分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id5">3.2.3. 卡方分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id6">3.3. 极限理论</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id7">3.3.1. 马尔可夫和切比雪夫不等式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id8">3.3.2. 弱大数定律</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id9">3.3.3. 依概率收敛</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-clt">3.3.4. 中心极限定理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id11">3.3.5. 强大数定理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id12">3.4. 似然估计量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id13">3.4.1. 估计量的偏差与方差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-2-fisher-information">3.4.2. 信息量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-2-mle-estimator">3.4.3. 最大似然估计的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-influence-test-interval">3.5. 置信区间</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#z">3.5.1. 均值参数的 Z 区间估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id18">3.5.2. 均值参数的 T 区间估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id19">3.5.3. 方差参数的区间估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-influence-test-test">3.6. 简单假设检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id22">3.6.1. Z检验</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id23">3.6.2. T检验</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#id24">3.6.3. 卡方检验</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html">4. 指数族</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#ch-24-1">4.1. 指数族的定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id3">4.1.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id4">4.1.2. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id5">4.1.3. 泊松分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id6">4.1.4. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id7">4.1.5. 其它常见指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#ch-24-moments">4.2. 指数族的期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#id9">4.3. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%97%8F/content.html#kl">4.4. 最大似然估计与KL散度的关系</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html">5. 线性回归模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id2">5.1. 最小二乘</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id3">5.1.1. 最小误差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id4">5.1.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id5">5.2. 线性回归的概率解释</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id6">5.2.1. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/content.html#id7">5.2.2. 参数估计</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html">6. 广义线性模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id2">6.1. 指数族分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id3">6.1.1. 自然指数族</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id4">6.1.2. 示例：高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id5">6.1.3. 示例：伯努利分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id6">6.2. 广义线性模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/content.html#id7">6.3. 例子</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html">7. 参数估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#ch-glm-estimate">7.1. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id3">7.2. 泰勒级数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id4">7.3. 梯度下降法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id6">7.4. 牛顿法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id7">7.4.1. 算法推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id8">7.4.2. 标准连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id9">7.4.3. 迭代初始值的设定</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#irls">7.5. 迭代重加权最小二乘(IRLS)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id10">7.5.1. 算法推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id11">7.5.2. 算法过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#id12">7.6. 估计量的标准误差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/estimate.html#ch-glm-estimate-phi">7.7. 分散参数的估计</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="content.html">8. 模型评估</a><ul>
<li class="toctree-l3"><a class="reference internal" href="content.html#id2">8.1. 拟合优度</a><ul>
<li class="toctree-l4"><a class="reference internal" href="content.html#id3">8.1.1. 嵌套模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="content.html#likelihood-ratio">8.1.2. 对数似然比(Likelihood ratio)</a></li>
<li class="toctree-l4"><a class="reference internal" href="content.html#deviance">8.1.3. 偏差(deviance)</a></li>
<li class="toctree-l4"><a class="reference internal" href="content.html#r-2">8.1.4. 决定系数 <span class="math notranslate nohighlight">\(R^2\)</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="content.html#ch-glm-gof-chi">8.1.5. 广义皮尔逊卡方统计量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="content.html#residual-analysis">8.2. 残差分析(Residual analysis)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="content.html#response-residuals">8.2.1. Response residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="content.html#working-residuals">8.2.2. Working residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="content.html#partial-residuals">8.2.3. Partial residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="content.html#pearson-residuals">8.2.4. Pearson residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="content.html#deviance-residuals">8.2.5. Deviance residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="content.html#score-residuals">8.2.6. Score residuals</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="content.html#model-selection">8.3. 模型选择(model selection)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="content.html#aic">8.3.1. AIC</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="influence.html">9. 模型检验</a><ul>
<li class="toctree-l3"><a class="reference internal" href="influence.html#id2">9.1. 拉格朗日乘子检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="influence.html#id3">9.1.1. 得分统计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="influence.html#id4">9.1.2. 检验过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="influence.html#wald">9.2. wald 检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="influence.html#id5">9.2.1. 参数估计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="influence.html#id6">9.2.2. 检验过程</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="influence.html#id7">9.3. 似然比检验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="influence.html#id8">9.3.1. 抽样分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="influence.html#id9">9.3.2. 模型比较</a></li>
<li class="toctree-l4"><a class="reference internal" href="influence.html#id10">9.3.3. 偏差统计量</a></li>
<li class="toctree-l4"><a class="reference internal" href="influence.html#f">9.3.4. F 检验</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="influence.html#id11">9.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html">10. 高斯模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id2">10.1. 传统线性回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id3">10.2. 高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id4">10.3. 高斯回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id5">10.4. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id6">10.4.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#irls">10.4.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id7">10.4.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id10">10.5. 其它连接函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html">11. 逆高斯模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id2">11.1. 逆高斯分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id3">11.2. 逆高斯回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id4">11.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id5">11.3.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#irls">11.3.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id6">11.3.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%80%86%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/content.html#id7">11.4. 其它连接函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html">12. 二项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id2">12.1. 伯努利分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id3">12.2. 逻辑回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id4">12.2.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id5">12.2.2. 参数估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#odds-logit">12.2.3. odds 与 logit</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id6">12.3. 二项式分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id7">12.4. 二项式回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id8">12.4.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id9">12.4.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id10">12.5. 其它连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id11">12.5.1. 恒等连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#probit">12.5.2. probit 回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#log-log-clog-log">12.5.3. log-log 和 clog-log</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id12">12.6. 分组数据与比例数据</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html">13. 泊松模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#poisson">13.1. 泊松(Poisson)分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id2">13.1.1. 推导过程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id3">13.1.2. 泊松分布的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id5">13.2. 泊松回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id6">13.3. 参数估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id7">13.4. 拟合统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id8">13.5. 频率模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%B3%8A%E6%9D%BE%E6%A8%A1%E5%9E%8B/content.html#id9">13.6. 泊松模型的局限性</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html">14. 指数模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#exponential">14.1. 指数(exponential)分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id2">14.1.1. 推导过程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id3">14.1.2. 分布的特性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id6">14.2. 指数回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id7">14.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id8">14.3.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#id9">14.3.2. 拟合优度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%8C%87%E6%95%B0%E6%A8%A1%E5%9E%8B/content.html#irls">14.3.3. IRLS</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html">15. Gamma 模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id1">15.1. Gamma 函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id2">15.2. Gamma 分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id3">15.3. Gamma 回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id4">15.4. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id5">15.4.1. 似然函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#irls">15.4.2. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id6">15.4.3. 拟合优度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id7">15.5. 其他连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#id8">15.5.1. 对数 Gamma 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../gamma%E6%A8%A1%E5%9E%8B/content.html#identity-gamma">15.5.2. 恒等(identity) Gamma 模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html">16. 过度分散</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id2">16.1. 什么是过度分散</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id3">16.2. 过度分散的检测</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id4">16.3. 过度分散的影响</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%BF%87%E5%BA%A6%E5%88%86%E6%95%A3/content.html#id5">16.4. 标准误差的修正</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html">17. 负二项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id2">17.1. 负二项式分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id3">17.1.1. 从二项式分布推导</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id4">17.1.2. 泊松-伽马混合分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#alpha">17.1.3. 辅助参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的影响</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id5">17.2. 负二项回归模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id6">17.3. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#irls">17.3.1. IRLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id7">17.3.2. 参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id8">17.4. 负二项式模型扩展</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id9">17.4.1. 对数连接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id10">17.4.2. 参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 的估计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id11">17.4.3. 几何模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E8%B4%9F%E4%BA%8C%E9%A1%B9%E6%A8%A1%E5%9E%8B/content.html#id12">17.4.4. 广义负二项式模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html">18. 零计数问题</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id2">18.1. 零截断模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id3">18.1.1. 零截断泊松模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id4">18.1.2. 零截断负二项式模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#id5">18.2. 零膨胀模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#hurdle">18.2.1. Hurdle 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E9%9B%B6%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/content.html#zero-inflate">18.2.2. Zero-inflate 模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html">19. 多项式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id2">19.1. 类别分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#softmax">19.2. softmax 回归模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id3">19.2.1. 模型定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id4">19.2.2. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id5">19.3. 多项式分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%97%A0%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id6">19.4. 多项式回归模型</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html">20. 有序离散模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id2">20.1. 有序逻辑回归</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id3">20.2. 参数估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id4">20.3. 连接函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#logit">20.3.1. logit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#probit">20.3.2. probit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#clog-log">20.3.3. clog-log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#log-log">20.3.4. log-log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#cauchit">20.3.5. cauchit</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../%E6%9C%89%E5%BA%8F%E7%A6%BB%E6%95%A3%E6%A8%A1%E5%9E%8B/content.html#id5">20.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html">附录</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html#id2">标准正态累积分布表</a></li>
<li class="toctree-l3"><a class="reference internal" href="../%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E8%A1%A8.html#id3">卡方分布临界值表</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/content.html">参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../probability_model/index_html.html">概率图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html">1. 概率基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id2">1.1. 概率分布</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id3">1.2. 独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#marginalization">1.3. 边缘化(marginalization)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id6">1.4. 贝叶斯定理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id7">1.5. 期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id8">1.6. 常见概率分布</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id9">1.6.1. 离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id10">1.6.2. 连续变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id11">1.6.3. 计数变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id12">1.7. 大数定律</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id13">1.7.1. 独立同分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id14">1.7.2. 中心极限定理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id15">1.8. 信息论基础</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id16">1.8.1. 信息熵</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#kl">1.8.2. KL散度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/1.%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80.html#id18">1.8.3. 互信息</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html">2. 参数估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-liklihood">2.1. 极大似然估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id3">2.1.1. 二值离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id4">2.1.2. 一般离散变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-2-gaussian-ml">2.1.3. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id6">2.1.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-bayesian-estimation">2.2. 贝叶斯估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id8">2.2.1. 伯努利变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id9">2.2.2. 类别变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id10">2.3. 最大后验估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id11">2.3.1. 伯努利变量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id12">2.3.2. 类别变量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id13">2.4. 最大似然估计与贝叶斯估计的对比</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id14">2.5. 统计量和充分统计量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#fisher-information">2.6. Fisher Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id15">2.7. 估计量的评价</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id16">2.7.1. 估计量的方差与偏差</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#id17">2.7.2. 大数定律和中心极限定理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-2-mle-estimator">2.7.3. 最大似然估计的特性</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html">3. 指数族</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#ch-24-1">3.1. 指数族的定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id3">3.1.1. 伯努利分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id4">3.1.2. 类别分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id5">3.1.3. 泊松分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id6">3.1.4. 高斯分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id7">3.1.5. 其它常见指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#ch-24-moments">3.2. 指数族的期望与方差</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#id9">3.3. 最大似然估计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/18.%E6%8C%87%E6%95%B0%E6%97%8F_24.html#kl">3.4. 最大似然估计与KL散度的关系</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/19.%E5%A4%9A%E7%BB%B4%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83_26.html">4. 多维高斯分布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html">5. 有向图(Directed Graphical Models)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id1">5.1. 有向图</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id2">5.2. 条件独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/4.%E6%9C%89%E5%90%91%E5%9B%BE_lecture_2.html#id3">5.3. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html">6. 无向图(Undirected Graphical Models)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id1">6.1. 无向图的定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id2">6.2. 条件独立性</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id3">6.3. 图的分解</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#vs">6.4. 有向图 vs 无向图</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id4">6.5. 树</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/5.%E6%97%A0%E5%90%91%E5%9B%BE_lecture_3.html#id5">6.6. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html">7. 因子图</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id2">7.1. 因子图的定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id3">7.2. 图模型之间的转换</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id4">7.2.1. 转换为因子图</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id5">7.2.2. 因子图转换为有向图</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#id6">7.3. 图模型的评价</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#i-map">7.3.1. I-map</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#d-map">7.3.2. D-map</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/6.%E5%9B%A0%E5%AD%90%E5%9B%BE_lecture_4.html#p-map">7.3.3. P-map</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95_lecture_7.html">8. 消元法(The Elimination Algorithm)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95_lecture_7.html#id1">8.1. 什么是模型的推断</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95_lecture_7.html#id2">8.2. 消元法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95_lecture_7.html#id3">8.2.1. 一个例子</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95_lecture_7.html#ch-condition-margin">8.2.2. 条件概率和边缘概率</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95_lecture_7.html#id5">8.2.3. 有向图的消元法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95_lecture_7.html#id6">8.2.4. 无向图的消元法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95_lecture_7.html#id7">8.3. 图消除</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/8.%E6%B6%88%E5%85%83%E6%B3%95_lecture_7.html#id9">8.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html">9. 加和乘积算法(sum-product algorithm)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id1">9.1. 树结构</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id2">9.2. 从消元法到信息传播</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id3">9.3. 树模型的和积算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id4">9.4. 因子图的和积算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id5">9.5. 类树结构图模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#polytrees">9.6. 多重树(polytrees)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/9.%E5%92%8C%E7%A7%AF%E7%AE%97%E6%B3%95_lecture_8.html#id6">9.7. 总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html">10. 最大后验估计</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id2">10.1. 最大后验概率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id3">10.2. 最大化后验的状态</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/11.%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1_lecture_11.html#id4">10.3. 本章总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html">11. 完整观测的参数学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id2">11.1. 有向图的参数学习</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id3">11.2. 无向图的参数学习</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id4">11.2.1. 成对二值变量模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/12.%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_20.html#id5">11.2.2. 一般二值变量模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html">12. 不完整观测的学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html#id2">12.1. 隐变量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html#em">12.2. 期望最大化算法(EM)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/13.%E4%B8%8D%E5%AE%8C%E6%95%B4%E8%A7%82%E6%B5%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0_lecture_22.html#id3">12.3. 隐马尔可夫模型的参数估计</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/14.%E5%9B%BE%E5%BD%A2%E7%BB%93%E6%9E%84%E7%9A%84%E5%AD%A6%E4%B9%A0_lecture_23.html">13. 有向图结构学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/16.%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD_lecture_17.html">14. 变分推断</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html">15. 马尔科夫蒙特卡洛</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#why-sampling">15.1. Why sampling？</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#monte-carlo">15.2. 蒙特卡罗(Monte Carlo)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#markov-chain">15.3. 马尔科夫链(Markov Chain)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id2">15.3.1. 一个例子</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#time-reversibility">15.3.2. 时间可逆性(Time Reversibility)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id3">15.3.3. 总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#markov-chain-monte-carlo">15.4. Markov Chain Monte Carlo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#metropolis-hastings">15.4.1. Metropolis-Hastings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id4">15.4.2. 例子：正态分布的采样</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#id5">15.4.3. 多变量采样</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#gibbs">15.4.4. Gibbs 采样</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#mixing-time">15.5. Mixing Time</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/17.%E9%87%87%E6%A0%B7%E6%B3%95_lecture_18.html#approximate-map-and-partitioning">15.6. Approximate MAP and Partitioning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html">16. 回归模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id2">16.1. 机器学习的概率解释</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id3">16.2. 经典线性回归</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id4">16.2.1. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id5">16.3. 线性回归的概率解释</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id6">16.3.1. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id7">16.4. 凸函数最优化问题</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/21.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92_29.html#id8">16.5. 岭回归</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html">17. 分类模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id2">17.1. 生成模型与判别模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id3">17.2. 线性回归与线性分类</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id4">17.3. 生成模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id5">17.3.1. 高斯判别模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id6">17.3.2. 朴素贝叶斯模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id7">17.3.3. 指数族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id8">17.4. 判别模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id9">17.4.1. 逻辑回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id10">17.4.2. 多分类</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id11">17.4.3. 最大熵模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#probit">17.4.4. Probit 回归</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#noisy-or">17.4.5. Noisy-OR 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/22.%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB_32.html#id12">17.4.6. 其它指数模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html">18. 广义线性模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id2">18.1. 定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id3">18.1.1. 指数族分布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id4">18.1.2. 链接函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id5">18.1.3. 例子</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id6">18.2. 参数估计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id7">18.2.1. 梯度下降法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id8">18.2.2. 牛顿法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#irls">18.2.3. 迭代重加权最小二乘(IRLS)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#goodness-of-fit">18.3. goodness of fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id9">18.4. 连续值响应模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id10">18.4.1. 高斯族</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#gamma">18.4.2. Gamma族</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id12">18.5. 二项响应模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id13">18.6. 多项响应模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id14">18.7. 计数响应模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id15">18.7.1. 泊松分布</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/25.%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B_34.html#id16">18.8. GLM扩展</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html">19. 混合模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id2">19.1. 混合模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id3">19.2. 高斯混合模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/31.%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B_41.html#id4">19.3. 参数估计</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/32.%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90_42.html">20. 因子分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/33.LDA_43.html">21. 主题模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/33.LDA_43.html#plsa">21.1. PLSA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/33.LDA_43.html#lda">21.2. LDA</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html">22. 隐马尔可夫模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id2">22.1. 隐马尔可夫模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id3">22.1.1. 马尔可夫模型和朴素贝叶斯模型的关系</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_model/26.%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB_36.html#id4">22.2. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/27.%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA_37.html">23. 条件随机场</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/28.%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%99%A8_38.html">24. 卡尔曼滤波器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/40.%E9%A1%B9%E7%9B%AE%E5%8F%8D%E5%BA%94%E7%90%86%E8%AE%BA_50.html">25. 项目反应理论</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/41.%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%9F%A5%E8%AF%86%E8%BF%BD%E8%B8%AA_51.html">26. 贝叶斯知识追踪</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_model/%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE.html">27. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../audio/index.html">语音技术</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../audio/feature.html">1. 音频特征</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id2">1.1. 认识声音</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id3">1.2. 认识声波</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id4">1.2.1. 物体的振动以及简谐振动</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id7">1.2.2. 什么是声波</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id8">1.2.3. 纯音和复合音</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#spectrum">1.2.4. 频谱 Spectrum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id10">1.2.5. 名词</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id13">1.3. 语音学</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id14">1.3.1. 发声原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id15">1.3.2. 听觉感应</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id16">1.4. 数字信号处理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id17">1.4.1. 模数转换</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#wav">1.4.2. 音频文件–WAV</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id18">1.5. 分帧与加窗</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id19">1.5.1. 预加重处理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id20">1.5.2. 分帧与加窗</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id21">1.6. 声音的感官度量</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#sound-pressure-level-spl">1.6.1. 声压与声压级(Sound Pressure Level,SPL)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#intensity-level-il">1.6.2. 声强与声强级(Intensity Level,IL）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id22">1.6.3. 声压与声强的关系</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id23">1.6.4. 响度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id24">1.6.5. 音量计算</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id25">1.6.6. 频率与音高</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id26">1.7. 时域分析</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id27">1.7.1. 短时能量</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id28">1.7.2. 短时平均幅度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id29">1.7.3. 短时过零率</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id31">1.8. 频域分析</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#spectrum-spectrogram">1.8.1. 声谱(spectrum)和时频谱(spectrogram)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#short-time-fourier-transform-stft">1.8.2. 短时傅里叶变换 Short-time Fourier transform (STFT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id33">1.8.3. 倒频谱</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id34">1.8.4. 色谱图</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id35">1.9. 小波域特征</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id36">1.9.1. 离散小波域变换</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id37">1.9.2. 小波域过零率</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id38">1.9.3. 小波域质心</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../audio/feature.html#id39">1.9.4. 小波域子带能量</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#mfcc">1.10. 语音识别的音频特征–MFCC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../audio/feature.html#id40">1.11. 参考资料</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../edm/index.html">教育领域数据挖掘</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../edm/bkt.html">1. 贝叶斯知识追踪(Bayesian Knowledge Tracing,BKT)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id1">1.1. 简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#hidden-markov-model-hmm">1.2. 隐马尔科夫模型(Hidden Markov Model,HMM)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id5">1.3. 贝叶斯知识追踪(Bayesian Knowledge Tracing,BKT)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#bkt">1.3.1. BKT的参数估计</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#item-response-theory-irt">1.4. 项目反映理论(Item Response Theory,IRT)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#bktirt">1.5. BKT结合IRT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id6">1.6. 实验</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id7">1.6.1. 数据集</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id8">1.6.2. 实验方法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id9">1.6.3. 实验结果</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id10">1.6.4. 项目代码</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id11">1.7. 未来工作</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id12">1.7.1. 题目难度的计算</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#irt">1.7.2. 多参数IRT模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../edm/bkt.html#id13">1.7.3. 参数估计算法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../edm/bkt.html#id14">1.8. 参考文献</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">张振虎的博客</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>模型检验</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/glm/source/模型评估/influence_bak.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1>模型检验<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h1>
<p>我们基于样本训练模型，基于样本计算模型拟合优度指标，并给出模型好坏的结论。
然而，这一切都是建立随机样本的基础上，模型拟合优度指标也是一个随机量，
我们的结论是根据样本推断(influence)得出的，推断得出结论不是百分百准确的，
这就需要同时给出这个结论的可靠程度，而这就是统计推断(statistical inference)所做的事情。</p>
<p>上一章我们介绍了 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 中评价模型拟合好坏程度的常见指标，以及这些指标的定义和计算方法，
但是没有说明如何根据指标值得出结论，本章我们探讨如何根据拟合优度指标的值得出模型优劣的结论，
以及结论的可靠程度。再讨论 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 推断方法前，先简单讲解一下统计学中的推断和检验的理论，
<code class="docutils literal notranslate"><span class="pre">GLM</span></code> 的推断过程就是统计学推断理论的一个应用。</p>
<div class="section" id="glm">
<h2><code class="docutils literal notranslate"><span class="pre">GLM</span></code> 中的抽样分布<a class="headerlink" href="#glm" title="永久链接至标题">¶</a></h2>
<p>无论是置信区间还是假设检验都需要知道统计量的抽样分布，
因此要对 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 拟合优度进度推断和检验，就要知道各个拟合优度指标的抽样分布。
本节我们推导一下 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 中一些关键统计量的抽样分布。</p>
<p>如果响应变量是正态分布，则通常可以准确确定一些统计量的抽样分布。
反之，如果响应变量不是正态分布，就需要依赖中心极限定理，找到其大样本下的近似分布。
注意，这些结论的成立都是有一些前提条件的，
对于来自属于指数族分布的观测数据，特别是对于广义线性模型，确实满足了必要条件。
在本节我们只给出统计量抽样分布的一些关键步骤，
Fahrmeir和Kaufmann（1985）给出了广义线性模型抽样分布理论的详细信息。</p>
<p>如果一个统计量 <span class="math notranslate nohighlight">\(S\)</span>，其渐近服从正态分布 <span class="math notranslate nohighlight">\(S \sim \mathcal{N}(\mathbb{E}[S],V(S))\)</span>
，其中 <span class="math notranslate nohighlight">\(\mathbb{E}[S]\)</span> 和 <span class="math notranslate nohighlight">\(V(S)\)</span> 分别是 <span class="math notranslate nohighlight">\(S\)</span> 的期望和方差
，则近似的有：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-0">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-0" title="公式的永久链接">¶</a></span>\[\frac{S-\mathbb{E}[S]}{\sqrt{V(S)}} \sim \mathcal{N}(0,1)\]</div>
<p>根据卡方分布的定义，等价的有</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-1">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-1" title="公式的永久链接">¶</a></span>\[\frac{(S-\mathbb{E}[S])^2}{V(S)} \sim \chi^2 (1)\]</div>
<p>如果 <span class="math notranslate nohighlight">\(S\)</span> 是一个向量 <span class="math notranslate nohighlight">\(\pmb{S}^{T}=[S_1,\dots,S_k]\)</span> ，上述结论可以写成向量的模式。</p>
<div class="math notranslate nohighlight" id="equation-eq-influence-110">
<span class="eqno">()<a class="headerlink" href="#equation-eq-influence-110" title="公式的永久链接">¶</a></span>\[(\pmb{S}-\mathbb{E}[\pmb{S}])^T \pmb{V}^{-1}(\pmb{S}-\mathbb{E}[\pmb{S}])
\sim \chi^2 (k)\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\pmb{V}\)</span> 是协方差矩阵，并且必须是非奇异矩阵。</p>
<div class="section" id="id2">
<h3>得分统计量<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h3>
<p>我们已经知道似然函数及其一阶导数都是一个关于样本的函数，
所以似然函数及其一阶导数都是统计量(statistic)。
似然函数的一阶导数又叫做得分函数(score function)，也称为得分统计量(score statics)。
假设 <span class="math notranslate nohighlight">\(Y_1,\dots,Y_N\)</span> 是相互独立的 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 样本变量，
这里我们强调 <span class="math notranslate nohighlight">\(Y_i\)</span> 是一个随机变量，所以用大写符号表示。
其中有 <span class="math notranslate nohighlight">\(\mathbb{E}[Y_i]=\mu_i\)</span> , <span class="math notranslate nohighlight">\(g(\mu_i)=\beta^T x_i=\eta_i\)</span>
，自然参数 <span class="math notranslate nohighlight">\(\theta_i\)</span> 是一个关于 <span class="math notranslate nohighlight">\(\mu_i\)</span> 函数。
<code class="docutils literal notranslate"><span class="pre">GLM</span></code> 模型的对数似然函数为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-2">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-2" title="公式的永久链接">¶</a></span>\[\ell= \sum_{i=1}^N \left \{   \frac{Y_i \theta_i - b(\theta_i)}{a(\phi)}   + c(y_i,\phi)   \right \}\]</div>
<p>根据 <code class="xref std std-numref docutils literal notranslate"><span class="pre">章节%s</span></code> 的内容， <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 对数似然函数的一阶导数，得分统计量为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-3">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-3" title="公式的永久链接">¶</a></span>\[ \begin{align}\begin{aligned}U_j = \frac{ \partial \ell}{\beta_j}
&amp;= \sum_{i=1}^N \left ( \frac{\partial \ell_i}{\partial \theta_i} \right )
\left ( \frac{\partial \theta_i}{\partial \mu_i} \right )
\left ( \frac{\partial \mu_i}{\partial \eta_i} \right )
\left ( \frac{\partial \eta_i}{\partial \beta_j} \right )\\&amp;= \sum_{i=1}^N \left \{ \frac{Y_i-b'(\theta_i)}{a(\phi)}   \right \}
\left \{ \frac{1}{\nu(\mu_i)} \right \} \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{ij}\\&amp;= \sum_{i=1}^N \frac{Y_i-\mu_i}{a(\phi) \nu(\mu_i) } \left ( \frac{\partial \mu}{\partial \eta} \right )_i x_{ij}\\&amp;= \sum_{i=1}^N \frac{Y_i-\mu_i}{V(Y_i) } \left ( \frac{\partial \mu_i}{\partial \eta_i} \right ) x_{ij}\end{aligned}\end{align} \]</div>
<p>注意下标 <span class="math notranslate nohighlight">\(j\)</span> 表示的参数向量的下标，<span class="math notranslate nohighlight">\(U_j\)</span> 是 <span class="math notranslate nohighlight">\(\beta_j\)</span> 的一阶偏导数。
对于任意的样本 <span class="math notranslate nohighlight">\(Y_i\)</span> 都有 <span class="math notranslate nohighlight">\(\mathbb{E}[Y_i]=\mu_i\)</span>
，因此有：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-4">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-4" title="公式的永久链接">¶</a></span>\[\mathbb{E}_{Y_i}[U_j] = 0\]</div>
<p><span class="math notranslate nohighlight">\(U\)</span> 的协方差矩阵就是信息矩阵 <span class="math notranslate nohighlight">\(\mathcal{J}\)</span>。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-5">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-5" title="公式的永久链接">¶</a></span>\[\mathcal{J}_{jk} = \mathbb{E}[U_jU_k]\]</div>
<p>在  <a class="reference internal" href="../../../probability_model/2.%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.html#ch-estimate"><span class="std std-numref">章节2参数估计</span></a> 我们讲过，
信息矩阵 <span class="math notranslate nohighlight">\(\mathcal{J}\)</span> 又等于对数似然函数二阶偏导数的期望的负数，</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-6">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-6" title="公式的永久链接">¶</a></span>\[\mathcal{J} = - \mathbb{E}[\ell'']
= - \mathbb{E}[U']\]</div>
<p>如果模型的参数向量 <span class="math notranslate nohighlight">\(\beta\)</span> 只有一个截距参数， <span class="math notranslate nohighlight">\(\beta=[\beta_0]\)</span> ，
此时模型只有一个参数，得分统计量 <span class="math notranslate nohighlight">\(U\)</span> 是一个标量，其渐近服从正态分布。</p>
<div class="math notranslate nohighlight" id="equation-eq-glm-influence-015">
<span class="eqno">()<a class="headerlink" href="#equation-eq-glm-influence-015" title="公式的永久链接">¶</a></span>\[U  \sim \mathcal{N}(0,\mathcal{J})
\ \text{或者} \
\frac{U}{\sqrt{\mathcal{J}}} \sim \mathcal{N}(0,1)\]</div>
<p>根据卡方分布的定义，也可以写成</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-7">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-7" title="公式的永久链接">¶</a></span>\[\frac{U^2}{\mathcal{J}}  \sim \chi^2 (1)\]</div>
<p>如果 <span class="math notranslate nohighlight">\(\beta\)</span> 是一个参数向量，<span class="math notranslate nohighlight">\(\beta^T=[\beta_0,\beta_1,\dots,\beta_p]\)</span>，
模型一共有 <span class="math notranslate nohighlight">\(p+1\)</span> 个参数，
则 <span class="math notranslate nohighlight">\(\textbf{U}\)</span> 表示一个向量 <span class="math notranslate nohighlight">\(\textbf{U}^T=[U_0,U_1,\dots,U_p]\)</span>
，此时 <span class="math notranslate nohighlight">\(\textbf{U}\)</span> 渐近服从多维正态分布(multivariate Normal distribution,MVN)。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-8">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-8" title="公式的永久链接">¶</a></span>\[\textbf{U} \sim MVN(\textbf{0},\mathbf{\mathcal{J}})\]</div>
<p>在大样本下有</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-9">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-9" title="公式的永久链接">¶</a></span>\[\textbf{U}^T \mathbf{\mathcal{J}}^{-1} \textbf{U} \sim  \chi^2 (p+1)\]</div>
<div class="section" id="id3">
<h4>高斯分布的得分统计量<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h4>
<p>令 <span class="math notranslate nohighlight">\(Y_1,\dots,Y_N\)</span> 是独立同分布的高斯随机变量，<span class="math notranslate nohighlight">\(Y_i \sim \mathcal{N}(\mu,\sigma^2)\)</span>
，其中 <span class="math notranslate nohighlight">\(\mu\)</span> 是未知的， <span class="math notranslate nohighlight">\(\sigma^2\)</span> 是已知的常量，
并且所有变量 <span class="math notranslate nohighlight">\(Y_i\)</span> 都是拥有同样的均值参数 <span class="math notranslate nohighlight">\(\mu\)</span> 和常量方差 <span class="math notranslate nohighlight">\(\sigma^2\)</span> 。
其对数似然函数为：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-10">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-10" title="公式的永久链接">¶</a></span>\[\ell(\mu;Y,\sigma) = -\frac{1}{2\sigma^2} \sum_{i=1}^N (Y_i -\mu)^2 - N \ln (\sigma \sqrt{2\pi})\]</div>
<p>其得分统计量为</p>
<div class="math notranslate nohighlight" id="equation-eq-glm-influence-020">
<span class="eqno">()<a class="headerlink" href="#equation-eq-glm-influence-020" title="公式的永久链接">¶</a></span>\[U = \frac{d \ell}{d \mu} = \frac{1}{\sigma^2} \sum_{i=1}^N (Y_i -\mu)\]</div>
<p>可以把样本均值统计量 <span class="math notranslate nohighlight">\(\sum_{i=1}^N Y_i = N \bar{Y}\)</span> 代入到 <span class="math notranslate nohighlight">\(U\)</span> ，</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-11">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-11" title="公式的永久链接">¶</a></span>\[U = \frac{1}{\sigma^2} ( N \bar{Y} - N \mu)
=\frac{N}{\sigma^2} (\bar{Y} - \mu)\]</div>
<p>通过令 <span class="math notranslate nohighlight">\(U=0\)</span> 可以得到参数 <span class="math notranslate nohighlight">\(\mu\)</span> 的最大似然估计量 <span class="math notranslate nohighlight">\(\hat{\mu}=\bar{Y}\)</span>
。</p>
<p>现在看下统计量 <span class="math notranslate nohighlight">\(U\)</span> 的期望和方差，其期望是</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-12">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-12" title="公式的永久链接">¶</a></span>\[\mathbb{E}[U] = \frac{N}{\sigma^2} ( \mathbb{E}[\bar{Y}] - \mu)
= \frac{N}{\sigma^2} ( \mu - \mu) =0\]</div>
<p>统计量 <span class="math notranslate nohighlight">\(U\)</span> 的方差是</p>
<div class="math notranslate nohighlight" id="equation-eq-glm-influence-021">
<span class="eqno">()<a class="headerlink" href="#equation-eq-glm-influence-021" title="公式的永久链接">¶</a></span>\[ \begin{align}\begin{aligned}V(U)
&amp;= V \left[   \frac{1}{\sigma^2} \sum_{i=1}^N (Y_i -\mu)  \right]\\&amp;=\frac{1}{\sigma^4}  V \left[  \sum_{i=1}^N (Y_i -\mu)  \right]\\&amp;= \frac{1}{\sigma^4}  \sum_{i=1}^N V(Y_i)\\&amp;= \frac{N}{\sigma^2}\\&amp;= \mathcal{J}\end{aligned}\end{align} \]</div>
<p>结合 <a class="reference internal" href="#equation-eq-glm-influence-020">公式()</a> 和 <a class="reference internal" href="#equation-eq-glm-influence-021">公式()</a> 有</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-13">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-13" title="公式的永久链接">¶</a></span>\[\frac{U}{\sqrt{\mathcal{J}}} = \frac{\sqrt{N}(\bar{Y} - \mu)}{\sigma}\]</div>
</div>
<div class="section" id="id4">
<h4>二项分布的得分统计量<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h4>
<p>现在假设 <span class="math notranslate nohighlight">\(Y_i \sim Bin(n,\pi)\)</span>，
对数似然函数为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-14">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-14" title="公式的永久链接">¶</a></span>\[\ell(\pi;y) = \sum_{i=1}^N \left [ Y_i \ln \pi +(n-Y_i) \ln (1-\pi) + \ln \binom{n}{Y_i}
\right ]\]</div>
<p>得分统计量是</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-15">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-15" title="公式的永久链接">¶</a></span>\[ \begin{align}\begin{aligned}U &amp;=\frac{d \ell}{d \pi}\\&amp;=\sum_{i=1}^N \left [ \frac{Y_i}{\pi} - \frac{n-Y_i}{1-\pi} \right ]\\&amp;= \sum_{i=1}^N  \frac{Y_i-n\pi}{\pi(1-\pi)}\\&amp;= \frac{1}{\pi(1-\pi)} \sum_{i=1}^N  (Y_i-n\pi)\end{aligned}\end{align} \]</div>
<p>然后代入样本均值统计量， <span class="math notranslate nohighlight">\(\sum_{i=1}^N Y_i = N\bar{Y}\)</span> ，可以把 <span class="math notranslate nohighlight">\(U\)</span> 改写成</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-16">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-16" title="公式的永久链接">¶</a></span>\[U = \frac{ N(\bar{Y} - n\pi)}{\pi(1-\pi)}\]</div>
<p>因为 <span class="math notranslate nohighlight">\(\mathbb{E}[Y_i]=n\pi\)</span> ，
所以 <span class="math notranslate nohighlight">\(\mathbb{E}[U]=0\)</span>。
又因为 <span class="math notranslate nohighlight">\(V(Y_i) = n\pi(1-\pi)\)</span>
，所以</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-17">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-17" title="公式的永久链接">¶</a></span>\[ \begin{align}\begin{aligned}V(U)
&amp;=V\left[     \sum_{i=1}^N  \frac{Y_i-n\pi}{\pi(1-\pi)}      \right ]\\&amp;= \frac{1}{\pi^2(1-\pi)^2} V \left [ \sum_{i=1}^N (Y_i-n\pi)      \right]\\&amp;= \frac{1}{\pi^2(1-\pi)^2} \sum_{i=1}^N V(Y_i-n\pi)\\&amp;= \frac{1}{\pi^2(1-\pi)^2} \sum_{i=1}^N V(Y_i)\\&amp;= \frac{Nn}{\pi(1-\pi)}\\&amp;= \mathcal{J}\end{aligned}\end{align} \]</div>
<p>因此有</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-18">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-18" title="公式的永久链接">¶</a></span>\[\frac{U}{\sqrt{J}} = \frac{\sqrt{N}(\bar{Y}-n\pi)}{\sqrt{n\pi(1-\pi)}}
\sim \mathcal{N}(0,1)\]</div>
</div>
</div>
<div class="section" id="ch-influence-ml-statistic">
<span id="id5"></span><h3>参数估计量<a class="headerlink" href="#ch-influence-ml-statistic" title="永久链接至标题">¶</a></h3>
<p>在讨论参数估计量的抽样分布前，先回顾一下泰勒级数近似(Taylor series approximation)，
后续统计量抽样分布的推导依赖泰勒级数。</p>
<div class="topic">
<p class="topic-title">泰勒级数</p>
<p>定义一个单变量的函数 <span class="math notranslate nohighlight">\(f(x)\)</span>，
对于函数上的某个点 <span class="math notranslate nohighlight">\(x=t\)</span> 的附近有如下近似成立：</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-19">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-19" title="公式的永久链接">¶</a></span>\[f(x) = f(t) + (x-t)\left[ \frac{df}{dx} \right]_{x=t}
+ \frac{1}{2}(x-t)^2 \left[ \frac{d^2f}{d x^2}  \right ]_{x=t}
+ \dots\]</div>
</div>
<p>本节我们利用泰勒级数推导 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 中协变量参数 <span class="math notranslate nohighlight">\(\beta\)</span>
的似然估计量 <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> 的抽样分布。
为了便于理解，我们先用空模型进行推导，然后再扩展到一般模型。</p>
<p><strong>空模型</strong></p>
<p>对于空模型，模型只有一个截距参数 <span class="math notranslate nohighlight">\(\beta=[\beta_0]\)</span>，
假设截距参数 <span class="math notranslate nohighlight">\(\beta_0\)</span> 的估计值是 <span class="math notranslate nohighlight">\(\hat{\beta}\)</span>
，在估计值 <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> 的附近用泰勒级数展开为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-20">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-20" title="公式的永久链接">¶</a></span>\[\ell(\beta) = \ell(\hat{\beta}) + (\beta-\hat{\beta})U(\hat{\beta})
+ \frac{1}{2}(\beta-\hat{\beta})^2 U'(\hat{\beta})\]</div>
<p>其中 <span class="math notranslate nohighlight">\(U(\hat{\beta})\)</span> 表示 <span class="math notranslate nohighlight">\(\ell(\beta=\hat{\beta})\)</span> 的一阶导数，
用 <span class="math notranslate nohighlight">\(U'(\hat{\beta})\)</span> 表示 <span class="math notranslate nohighlight">\(\ell(\beta=\hat{\beta})\)</span> 的二阶导数。
我们知道 <span class="math notranslate nohighlight">\(\mathbb{E}[U']=-\mathcal{J}\)</span>
，现在我们用 <span class="math notranslate nohighlight">\(U'(\hat{\beta})\)</span> 的期望值代 <span class="math notranslate nohighlight">\(-\mathcal{J}(\hat{\beta})\)</span> 替其自身，</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-21">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-21" title="公式的永久链接">¶</a></span>\[\ell(\beta) = \ell(\hat{\beta}) + (\beta-\hat{\beta})U(\hat{\beta})
- \frac{1}{2}(\beta-\hat{\beta})^2 \mathcal{J}(\hat{\beta})\]</div>
<p>现在我们把得分函数 <span class="math notranslate nohighlight">\(U\)</span> 在 <span class="math notranslate nohighlight">\(\beta=\hat{\beta}\)</span> 的附近展开，
但这里我们只要前两项，忽略二阶以及更高阶的项。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-22">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-22" title="公式的永久链接">¶</a></span>\[U(\beta) = U(\hat{\beta}) + (\beta-\hat{\beta}) U'(\hat{\beta})\]</div>
<p>同样，可以用 <span class="math notranslate nohighlight">\(-\mathcal{J}\)</span> 代替 <span class="math notranslate nohighlight">\(U'(\hat{\beta})\)</span>，</p>
<div class="math notranslate nohighlight" id="equation-eq-me-122">
<span class="eqno">()<a class="headerlink" href="#equation-eq-me-122" title="公式的永久链接">¶</a></span>\[U(\beta) = U(\hat{\beta}) - (\beta-\hat{\beta}) \mathcal{J}(\hat{\beta})\]</div>
<p><strong>一般模型</strong></p>
<p>如果是一般模型，模型的协变量参数 <span class="math notranslate nohighlight">\(\beta\)</span> 是一个向量，
上述推导过程仍然适用，只需要把标量参数改成向量参数即可。</p>
<div class="math notranslate nohighlight" id="equation-eq-influence-250">
<span class="eqno">()<a class="headerlink" href="#equation-eq-influence-250" title="公式的永久链接">¶</a></span>\[\ell(\pmb{\beta}) = \ell(\pmb{\hat{\beta}}) + (\pmb{\beta}-\pmb{\hat{\beta}})^T \mathbf{U}(\pmb{\hat{\beta}})
- \frac{1}{2}(\pmb{\beta}-\pmb{\hat{\beta}})^T \pmb{\mathcal{J}}(\pmb{\hat{\beta}})(\pmb{\beta}-\pmb{\hat{\beta}})\]</div>
<p><a class="reference internal" href="#equation-eq-me-122">公式()</a> 的向量版本为</p>
<div class="math notranslate nohighlight" id="equation-eq-influence-251">
<span class="eqno">()<a class="headerlink" href="#equation-eq-influence-251" title="公式的永久链接">¶</a></span>\[\mathbf{U}(\pmb{\beta}) = \mathbf{U}(\pmb{\hat{\beta}}) -
(\pmb{\beta}-\pmb{\hat{\beta}}) \pmb{\mathcal{J}}(\pmb{\hat{\beta}})\]</div>
<p>标量和向量在公式以及推导上没有本质区别，所以后续不再用粗体进行区分，默认都是向量。</p>
<p>公式中 <span class="math notranslate nohighlight">\(U(\hat{\beta})\)</span> 是对数似然函数的在 <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> 处的一阶导数，
而 <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> 是通过令 <span class="math notranslate nohighlight">\(U(\beta)=0\)</span> 得到似然估计值，
显然有 <span class="math notranslate nohighlight">\(U(\hat{\beta})=0\)</span> 成立。
因此 <a class="reference internal" href="#equation-eq-me-122">公式()</a> 或者 <a class="reference internal" href="#equation-eq-influence-251">公式()</a> 可以简写成</p>
<div class="math notranslate nohighlight" id="equation-eq-glm-influence-085">
<span class="eqno">()<a class="headerlink" href="#equation-eq-glm-influence-085" title="公式的永久链接">¶</a></span>\[    U(\beta) = - (\beta-\hat{\beta}) \mathcal{J}(\hat{\beta})
    = (\hat{\beta}-\beta) \mathcal{J}(\hat{\beta})\]</div>
<p>根据上一节的结论（<a class="reference internal" href="#equation-eq-glm-influence-015">公式()</a>），统计量 <span class="math notranslate nohighlight">\(U/\sqrt{\mathcal{J}}\)</span>
的抽样分布是标准高斯分布。</p>
<div class="math notranslate nohighlight" id="equation-eq-glm-influence-086">
<span class="eqno">()<a class="headerlink" href="#equation-eq-glm-influence-086" title="公式的永久链接">¶</a></span>\[\frac{U}{\sqrt{\mathcal{J}}} \sim \mathcal{N}(0,1)\]</div>
<p><a class="reference internal" href="#equation-eq-glm-influence-085">公式()</a> 代入 <a class="reference internal" href="#equation-eq-glm-influence-086">公式()</a> 可得</p>
<div class="math notranslate nohighlight" id="equation-eq-glm-influence-087">
<span class="eqno">()<a class="headerlink" href="#equation-eq-glm-influence-087" title="公式的永久链接">¶</a></span>\[\frac{(\hat{\beta}-\beta) \mathcal{J}(\hat{\beta}) }{ \sqrt{\mathcal{J}(\hat{\beta})} }
= \frac{(\hat{\beta}-\beta)  }{ \sqrt{\mathcal{J}(\hat{\beta})^{-1} } }
\sim \mathcal{N}(0,1)\]</div>
<p>我们知道 <span class="math notranslate nohighlight">\(\mathbb{E}[U]=0\)</span> ，
如果把 <span class="math notranslate nohighlight">\(\mathcal{J}\)</span> 看做一个常量，<span class="math notranslate nohighlight">\(\beta\)</span> 是参数的真实值，
则有</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-23">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-23" title="公式的永久链接">¶</a></span>\[ \begin{align}\begin{aligned}\mathbb{E}[U(\beta)] &amp;= \mathbb{E} [  (\hat{\beta}-\beta) \mathcal{J}(\hat{\beta})  ]\\&amp;= \mathcal{J}(\hat{\beta})  \mathbb{E}[(\hat{\beta}-\beta) ]\\&amp;= \mathcal{J}(\hat{\beta}) ( \mathbb{E}[\hat{\beta}] -\beta)\\&amp;=0\end{aligned}\end{align} \]</div>
<p>因此有</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-24">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-24" title="公式的永久链接">¶</a></span>\[\mathbb{E}[\hat{\beta}]= \beta\]</div>
<p>现在来看下估计量 <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> 的方差 <span class="math notranslate nohighlight">\(V(\hat{\beta})\)</span> 。
首先变换下 <a class="reference internal" href="#equation-eq-glm-influence-085">公式()</a> 可得</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-25">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-25" title="公式的永久链接">¶</a></span>\[\hat{\beta}-\beta = \frac{U(\beta)}{\mathcal{J}(\hat{\beta})}\]</div>
<p>然后有</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-26">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-26" title="公式的永久链接">¶</a></span>\[ \begin{align}\begin{aligned}V(\hat{\beta}) &amp;= \mathbb{E} \left [ (\hat{\beta} -\mathbb{E}[\hat{\beta}]) (\hat{\beta}-\mathbb{E}[\hat{\beta}])^T \right ]\\&amp;= \mathbb{E} \left[ (\hat{\beta} -\beta) (\hat{\beta} -\beta)^T \right ]\\&amp;= \mathbb{E} \left[ \mathcal{J}^{-1}U U^T \mathcal{J}^{-1} \right ]\\&amp;= \mathcal{J}^{-1} \mathbb{E} \left[ U U^T  \right ] \mathcal{J}^{-1}\\&amp;= \mathcal{J}^{-1}\end{aligned}\end{align} \]</div>
<p>最后总结下，参数估计量 <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> 的期望为参数真值 <span class="math notranslate nohighlight">\(\beta\)</span>，
方差为 <span class="math notranslate nohighlight">\(\mathcal{J}^{-1}\)</span>。
结合 <a class="reference internal" href="#equation-eq-glm-influence-087">公式()</a>，
参数估计量的抽样分布是正态分布</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-27">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-27" title="公式的永久链接">¶</a></span>\[\hat{\beta} \sim \mathcal{N}(\beta, \mathcal{J}^{-1})\]</div>
<p>等价的表示是</p>
<div class="math notranslate nohighlight" id="equation-eq-glm-influence-090">
<span class="eqno">()<a class="headerlink" href="#equation-eq-glm-influence-090" title="公式的永久链接">¶</a></span>\[\frac{ \hat{\beta}-\beta  }{ \sqrt{\mathcal{J}(\hat{\beta})^{-1} } }
\sim \mathcal{N}(0,1)\]</div>
<p>如果 <span class="math notranslate nohighlight">\(Y\)</span> 的分布是正态分布，似然估计量 <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> 就是精确服从正态分布，而不是渐近了。
如果 <span class="math notranslate nohighlight">\(Y\)</span> 的分布是非正态分布，似然估计量 <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> 就是渐近服从正态分布。</p>
<p>参考本节开始时的理论（<a class="reference internal" href="#equation-eq-influence-110">公式()</a>）， <a class="reference internal" href="#equation-eq-glm-influence-090">公式()</a> 另一个等价的表示是</p>
<div class="math notranslate nohighlight" id="equation-eq-glm-influence-092">
<span class="eqno">()<a class="headerlink" href="#equation-eq-glm-influence-092" title="公式的永久链接">¶</a></span>\[(\hat{\beta}-\beta)^T\mathcal{J}(\hat{\beta})(\hat{\beta}-\beta) \sim \chi^2(p+1)\]</div>
<p><span class="math notranslate nohighlight">\(p\)</span> 是模型的特征数量，也是协变量参数的数量（不含截距参数），<span class="math notranslate nohighlight">\(p+1\)</span> 中的 <span class="math notranslate nohighlight">\(1\)</span> 代表截距参数，
<span class="math notranslate nohighlight">\(p+1\)</span> 就是模型的参数数量。
<a class="reference internal" href="#equation-eq-glm-influence-092">公式()</a> 又叫做 <code class="docutils literal notranslate"><span class="pre">Wald</span></code> 统计量。</p>
</div>
<div class="section" id="ch-influence-deviance">
<span id="id6"></span><h3>偏差统计量<a class="headerlink" href="#ch-influence-deviance" title="永久链接至标题">¶</a></h3>
<p>现在我们讨论下偏差统计量的抽样分布，
首先回顾一下泰勒展开式 <a class="reference internal" href="#equation-eq-influence-250">公式()</a> ，
其中满足 <span class="math notranslate nohighlight">\(U(\hat{\beta})=0\)</span>，
变化一下公式，则近似有如下等式成立。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-28">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-28" title="公式的永久链接">¶</a></span>\[\ell(\beta) - \ell(\hat{\beta}) = -\frac{1}{2}(\beta -\hat{\beta} )^T\mathcal{J}(\hat{\beta})(\beta-\hat{\beta})\]</div>
<p>继续移项，可得到如下统计量</p>
<div class="math notranslate nohighlight" id="equation-eq-influence-260">
<span class="eqno">()<a class="headerlink" href="#equation-eq-influence-260" title="公式的永久链接">¶</a></span>\[2[\ell(\hat{\beta}) - \ell(\beta) ] = (\hat{\beta} -\beta )^T\mathcal{J}(\hat{\beta})(\hat{\beta}-\beta)\]</div>
<p>依据 <a class="reference internal" href="#equation-eq-glm-influence-092">公式()</a> 这个统计量是服从自由度为 <span class="math notranslate nohighlight">\(p+1\)</span> 的卡方分布，<span class="math notranslate nohighlight">\(p+1\)</span>
是模型的参数数量。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-29">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-29" title="公式的永久链接">¶</a></span>\[2[\ell(\hat{\beta}) - \ell(\beta) ] \sim \chi^2(p+1)\]</div>
<p>仔细观察下这个统计量，其和偏差的定义基本是一致的。
我知道偏差(deviance) <span class="math notranslate nohighlight">\(D\)</span>
和对数似然比统计量(log-likelihood ratio statistic)是等价的，其计算公式为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-30">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-30" title="公式的永久链接">¶</a></span>\[D = 2[\ell(b_{s};y) - \ell(b_{f};y)]\]</div>
<p>其中，符号 <span class="math notranslate nohighlight">\(b_{s}\)</span> 表示饱和(𝑠𝑎𝑡𝑢𝑟𝑎𝑡𝑒𝑑)模型参数的最大似然估计量，
<span class="math notranslate nohighlight">\(\ell(b_{s};y)\)</span> 表示饱和模型的 <strong>似然统计量</strong>。
符号 <span class="math notranslate nohighlight">\(b_{f}\)</span> 表示我们目标拟合(𝑓𝑖𝑡𝑡𝑒𝑑)模型参数的最大似然估计量，
<span class="math notranslate nohighlight">\(\ell(b_{f};y)\)</span> 表示拟合模型的 <strong>似然统计量</strong> 。
注意二者是 <strong>统计量(随机变量)</strong>，不是数值量。
参数向量 <span class="math notranslate nohighlight">\(b_{s}\)</span> 和 <span class="math notranslate nohighlight">\(b_{f}\)</span> 的长度是不同的，
饱和模型的参数数量就等于样本容量 <span class="math notranslate nohighlight">\(N\)</span> ，
假设拟合模型的参数向量 <span class="math notranslate nohighlight">\(b_{f}\)</span> 的长度是 <span class="math notranslate nohighlight">\(p+1\)</span>， <span class="math notranslate nohighlight">\(p+1&lt;N\)</span>  。
现在我们把 <span class="math notranslate nohighlight">\(D\)</span> 变换一下。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-31">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-31" title="公式的永久链接">¶</a></span>\[ \begin{align}\begin{aligned}D &amp;= 2[\ell(b_{s};y) - \ell(b_{f};y)]
+ 2\ell(\beta_{s};y) - 2\ell(\beta_{s};y)
+ 2\ell(\beta_{f};y)  - 2\ell(\beta_{f};y)\\&amp;= \underbrace{2[ \ell(b_{s};y) -  \ell(\beta_{s};y)  ]}_{\chi^2(N)}
- \underbrace{2[ \ell(b_{f};y) - \ell(\beta_{f};y)  ]}_{\chi^2(p+1)}
+ \underbrace{2[ \ell(\beta_{s};y) - \ell(\beta_{f};y)   ]}_{\text{数值}v}\end{aligned}\end{align} \]</div>
<p>其中符号 <span class="math notranslate nohighlight">\(\ell(\beta_{s};y)\)</span> 表示饱和模型真实参数值的似然值（模型的理论最大似然值），是一个数值，不是统计量。
同理 <span class="math notranslate nohighlight">\(\ell(\beta_{f};y)\)</span> 是拟合模型的理论最大似然值，也是一个数值。
最终统计量 <span class="math notranslate nohighlight">\(D\)</span> 可以看做是由三部分组成，自由度为 <span class="math notranslate nohighlight">\(N\)</span> 卡方分布减去自由度为 <span class="math notranslate nohighlight">\(p+1\)</span> 的卡方分布，
再加上一个数值 <span class="math notranslate nohighlight">\(v\)</span> 。</p>
<p>根据卡方分布的特性，统计量 <span class="math notranslate nohighlight">\(D\)</span> 渐近服从 <strong>非中心卡方分布</strong> ，
其自由度是 <span class="math notranslate nohighlight">\(N-p-1\)</span> 。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-32">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-32" title="公式的永久链接">¶</a></span>\[D \sim \chi^2(N-p-1,v)\]</div>
<p>注意偏差统计量 <span class="math notranslate nohighlight">\(D\)</span> 是一个 <strong>非中心卡方分布</strong>，这和之前介绍的统计量不同，
<span class="math notranslate nohighlight">\(v\)</span> 是非中心参数。
<span class="math notranslate nohighlight">\(D\)</span> 的期望值是 <span class="math notranslate nohighlight">\(\mathbb{E}[D] = N-p-1+v\)</span> 。
现在来重点看一下 <span class="math notranslate nohighlight">\(v\)</span> 的值，</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-33">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-33" title="公式的永久链接">¶</a></span>\[v = 2[ \ell(\beta_{s};y) - \ell(\beta_{f};y)   ]\]</div>
<p><span class="math notranslate nohighlight">\(v\)</span> 的值是饱和模型的理论最大似然值和拟合模型的理论最大似然值的差，
前者 <span class="math notranslate nohighlight">\(\ell(\beta_{s};y)\)</span> 的值是固定不变的，
后者 <span class="math notranslate nohighlight">\(\ell(\beta_{f};y)\)</span> 是你的拟合模型的理论上限，
拟合模型的拟合效果越好，<span class="math notranslate nohighlight">\(\ell(\beta_{f};y)\)</span> 就越接近前者饱和模型，
<span class="math notranslate nohighlight">\(v\)</span> 的值也就越小。
极限情况下，拟合模型对样本的拟合能力和饱和模型一样好，此时 <span class="math notranslate nohighlight">\(v=0\)</span> 。
这时偏差 <span class="math notranslate nohighlight">\(D\)</span> 就是渐进服从 <strong>中心卡方分布</strong> <span class="math notranslate nohighlight">\(\chi^2(N-p-1)\)</span> 。
<strong>本节的内容是下一节的理论基础，对于理解检验过程非常重要。</strong>
<strong>如果难以理解本节的推导过程，可以先记住以下结论。</strong></p>
<div class="topic">
<p class="topic-title">重要结论</p>
<p>模型对数据拟合的越好(越接近饱和模型)，其偏差 <span class="math notranslate nohighlight">\(D\)</span> 就越接近中心卡方分布 <span class="math notranslate nohighlight">\(\chi^2(N-p-1)\)</span> ，
此时偏差统计量 <span class="math notranslate nohighlight">\(D\)</span> 的期望就越接近 <span class="math notranslate nohighlight">\(N-p-1\)</span> 。反之如果模型拟合的不好，偏差统计量 <span class="math notranslate nohighlight">\(D\)</span>
就是非中心卡方分布 <span class="math notranslate nohighlight">\(\chi^2(N-p-1,v)\)</span> ，其期望值就是 <span class="math notranslate nohighlight">\(v+N-p-1\)</span> ，相比于好的模型期望值会偏离 <span class="math notranslate nohighlight">\(N-p-1\)</span>
。后续的比较两个模型效果的假设检验过程就利用这个特性。</p>
</div>
<p>如果响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 是高斯分布，则偏差统计量 <span class="math notranslate nohighlight">\(D\)</span>
就是确切服从（非中心）卡方分布的，而不是渐近的。
如果响应变量 <span class="math notranslate nohighlight">\(Y\)</span> 不是高斯分布，则偏差统计量 <span class="math notranslate nohighlight">\(D\)</span>
是 <strong>渐近</strong> 服从（非中心）卡方分布的。这个特性我们已经多次强调过。</p>
<div class="admonition hint">
<p class="admonition-title">提示</p>
<p>统计量 <span class="math notranslate nohighlight">\(D\)</span> 的计算是需要根据对数似然值计算，而对数似然值的计算又需要计算 <span class="math notranslate nohighlight">\(V(Y_i)=a(\phi)\nu(\mu_i)\)</span>。
显然要计算对数似然值就需要知道模型的分散参数 <span class="math notranslate nohighlight">\(\phi\)</span> 的值。指数族中部分分布是没有分散参数 <span class="math notranslate nohighlight">\(\phi\)</span> 的，
比如二项分布、多项分布、泊松分布区等，这些模型可以直接计算出统计量 <span class="math notranslate nohighlight">\(D\)</span> 的值。然而，有些指数族分布，比如高斯分布，
就存在分散参数 <span class="math notranslate nohighlight">\(\phi=\sigma^2\)</span> ，此时理论上是无法直接计算出 <span class="math notranslate nohighlight">\(D\)</span> 的值。这时有两种解决方法，第一种方法是假设
<span class="math notranslate nohighlight">\(\phi\)</span> 为一个常量值，传统线性回归模型就是这么干的，其假设 <span class="math notranslate nohighlight">\(\phi=\sigma^2=1\)</span> 。
第二种方法就是利用其它估计方法得到 <span class="math notranslate nohighlight">\(\phi\)</span> 的一个估计值。</p>
</div>
</div>
</div>
<div class="section" id="id7">
<h2><code class="docutils literal notranslate"><span class="pre">GLM</span></code> 中的模型检验<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h2>
<p>我们已经知道偏差统计量是饱和模型的对数似然值和拟合模型的对数似然值的差，</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-34">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-34" title="公式的永久链接">¶</a></span>\[D = 2[\ell(b_{s};y) - \ell(b_{f};y)]\]</div>
<p>饱和模型的对数似然值 <span class="math notranslate nohighlight">\(\ell(b_{s};y)\)</span> 代表了模型似然值的理论最大值，
偏差的含义就是拟合模型的似然值和这个上限值差了多少，偏差越小说明拟合模型对数据的拟合度越好。
理论上偏差 <span class="math notranslate nohighlight">\(D\)</span> 的取值范围是 <span class="math notranslate nohighlight">\([0,+\infty]\)</span>
，然而实际上偏差 <span class="math notranslate nohighlight">\(D\)</span> 是不大可能得到一个接近0的值。
饱和模型虽然似然值最大，但其是一种极端过拟合(overfitted)的状态，没有学习到任何关于总体的特征，不具备丝毫泛化能力，
<strong>似然值最大并不意味着模型就一定是最好的</strong>。</p>
<p>为了保障模型能从样本数据中学习到总体特征，拟合模型的参数数量 <span class="math notranslate nohighlight">\(p\)</span> 必然是远小于样本容量 <span class="math notranslate nohighlight">\(N\)</span> 的，
拟合模型的似然值 <span class="math notranslate nohighlight">\(\ell(b_{f};y)\)</span> 也必然是远小于饱和模型的似然值 <span class="math notranslate nohighlight">\(\ell(b_{s};y)\)</span>
，因此偏差 <span class="math notranslate nohighlight">\(D\)</span> 通常会得到一个比较大的值。并且不同的样本、不同的模型必然会得到不同的 <span class="math notranslate nohighlight">\(D\)</span> 值，
通常差异也会比较大。那么当你计算出一个 <span class="math notranslate nohighlight">\(D\)</span> 值时，如何判断模型是好还是坏呢？以及你的结论可靠吗？
毕竟 <span class="math notranslate nohighlight">\(D\)</span> 是一个统计量(随机量)，仅根据一个值得出结论可信度有多高？
如果你彻底理解了 <a class="reference internal" href="../%E6%8E%A8%E6%96%AD%E4%B8%8E%E6%A3%80%E9%AA%8C/content.html#ch-influence-and-test"><span class="std std-numref">第3章</span></a> 的内容，那么此时你的脑海中应该已经有答案了。</p>
<div class="section" id="id8">
<h3>模型检验<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h3>
<div class="section" id="id9">
<h4>似然比检验<a class="headerlink" href="#id9" title="永久链接至标题">¶</a></h4>
</div>
<div class="section" id="wald">
<h4>Wald 检验<a class="headerlink" href="#wald" title="永久链接至标题">¶</a></h4>
</div>
<div class="section" id="id10">
<h4>拉格朗日乘子检验<a class="headerlink" href="#id10" title="永久链接至标题">¶</a></h4>
<p>Lagrange multiplier</p>
</div>
<div class="section" id="f">
<h4>F 检验<a class="headerlink" href="#f" title="永久链接至标题">¶</a></h4>
<p>我们知道偏差 <span class="math notranslate nohighlight">\(D\)</span> 是一个统计量，
并且其抽样分布是卡方分布 <span class="math notranslate nohighlight">\(\chi^2(N-p,v)\)</span> ，期望值是</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-35">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-35" title="公式的永久链接">¶</a></span>\[\mathbb{E}[D] = N-p+v\]</div>
<p>注意，样本容量 <span class="math notranslate nohighlight">\(N\)</span> 和模型参数数量 <span class="math notranslate nohighlight">\(p\)</span> 的值是已知的，
而 <span class="math notranslate nohighlight">\(v\)</span> 的值我们是无法计算出的。根据之前的结论，模型对数据拟合的越好，<span class="math notranslate nohighlight">\(v\)</span> 的值就越小，
<span class="math notranslate nohighlight">\(D\)</span> 的期望值就越接近 <span class="math notranslate nohighlight">\(N-p\)</span> 。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-36">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-36" title="公式的永久链接">¶</a></span>\[\mathbb{E}[D] = N-p\]</div>
<p>那么我们可以基于这个假设对偏差统计量 <span class="math notranslate nohighlight">\(D\)</span> 进行推断和检验，
如果模型对数据拟合的足够好，则统计量 <span class="math notranslate nohighlight">\(D\)</span> 的期望值就是
<span class="math notranslate nohighlight">\(N-p\)</span> ，反之期望值就是 <span class="math notranslate nohighlight">\(N-p+v\)</span> ，
基于此零假设 <span class="math notranslate nohighlight">\(H_0\)</span> 和备择假设 <span class="math notranslate nohighlight">\(H_1\)</span>
分别是</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-37">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-37" title="公式的永久链接">¶</a></span>\[ \begin{align}\begin{aligned}H_0 : \mathbb{E}[D] = N-p\\H_1 : \mathbb{E}[D] \ne N-p\end{aligned}\end{align} \]</div>
<p>假设显著水平为 <span class="math notranslate nohighlight">\(\alpha =0.05\)</span>
，然后根据统计量 <span class="math notranslate nohighlight">\(D\)</span> 的值 <span class="math notranslate nohighlight">\(D=d\)</span>
计算出 <span class="math notranslate nohighlight">\(P-Value\)</span> ，
<span class="math notranslate nohighlight">\(P\)</span> 值就是 <span class="math notranslate nohighlight">\(D\ge d\)</span> 的概率，
可以通过查卡方检验表直接得到。
通过比较 <span class="math notranslate nohighlight">\(P-Value\)</span> 和 <span class="math notranslate nohighlight">\(\alpha\)</span>
得出检验结论。</p>
</div>
<div class="section" id="id11">
<h4>置信区间<a class="headerlink" href="#id11" title="永久链接至标题">¶</a></h4>
</div>
</div>
<div class="section" id="id12">
<h3>模型比较<a class="headerlink" href="#id12" title="永久链接至标题">¶</a></h3>
<p>有些时候我们需要比较两个模型，利用偏差统计量和假设检验可以做到，但是这种方法只适用于嵌套模型。
在 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 中 ，要求两个模型具有相同的指数族分布，以及同样的连接函数，
被比较的两个模型只有线性预测器是不同的，一个参数多，一个参数少，换句话说一个使用的特征多，另一个使用的特征少。
<strong>这种模型比较通常可以用来判断某些特征是否有价值，对模型是否有足够的贡献</strong>。
显然理论上，两个模型参数不同，对数据的拟合度必然会略有不同，
两个模型的偏差统计量的值也必然会有一些差异。通常情况下，参数少的模型偏差会稍大一些。
假设两个模型之间偏差的差值为 <span class="math notranslate nohighlight">\(\Delta D\)</span>
，那么这个 <span class="math notranslate nohighlight">\(\Delta D\)</span> 能否证明两个模型对数据的拟合能力有本质的差别，
还是由于随机性导致？假设检验，又或者叫显著性检验，就是用来回答这个问题的。
<strong>显著性检验用于说明</strong> <span class="math notranslate nohighlight">\(\Delta D\)</span> <strong>能否证明两个模型的拟合能力有”显著性”的差异，</strong>
<strong>当然假设检验并不能给出百分百准确的结论，其只能依概率给出结论</strong>。</p>
<p>在 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 中，检验两个模型拟合能力是否有显著差异的一般性步骤是：</p>
<ol class="arabic simple">
<li><p>定义模型 <span class="math notranslate nohighlight">\(M_0\)</span> 对应着零假设 <span class="math notranslate nohighlight">\(H_0\)</span>，定义另一个更一般(参数更多)的模型 <span class="math notranslate nohighlight">\(M_1\)</span> 对应着备择假设 <span class="math notranslate nohighlight">\(H_a\)</span>。
零假设 <span class="math notranslate nohighlight">\(H_0\)</span> 表示模型 <span class="math notranslate nohighlight">\(M_0\)</span> 和 <span class="math notranslate nohighlight">\(M_1\)</span> 拟合度一样好，反之，
备择假设 <span class="math notranslate nohighlight">\(H_a\)</span> 表示  <span class="math notranslate nohighlight">\(M_0\)</span> 比  <span class="math notranslate nohighlight">\(M_1\)</span> 拟合度差。</p></li>
<li><p>训练模型 <span class="math notranslate nohighlight">\(M_0\)</span> ，然后计算一个拟合优度(goodness of fit,GOF)指标统计量 <span class="math notranslate nohighlight">\(G_0\)</span> 。同样训练模型 <span class="math notranslate nohighlight">\(M_1\)</span> 并计算拟合优度指标 <span class="math notranslate nohighlight">\(G_1\)</span> 。</p></li>
<li><p>计算两个模型拟合度的差异，通常可以是 <span class="math notranslate nohighlight">\(\Delta G=G_1-G_0\)</span> ，或者是 <span class="math notranslate nohighlight">\(\Delta G=G_1/G_0\)</span> 。</p></li>
<li><p>使用差值统计量 <span class="math notranslate nohighlight">\(\Delta G\)</span> 的抽样分布检验接受假设 <span class="math notranslate nohighlight">\(G_1=G_0\)</span> 还是 <span class="math notranslate nohighlight">\(G_1 \ne G_0\)</span></p></li>
<li><p>如果假设 <span class="math notranslate nohighlight">\(G_1=G_0\)</span> 没有被拒绝，则接受 <span class="math notranslate nohighlight">\(H_0\)</span> 。反之，如果假设 <span class="math notranslate nohighlight">\(G_1=G_0\)</span> 被拒绝，则接受备择假设 <span class="math notranslate nohighlight">\(H_a\)</span>，
<span class="math notranslate nohighlight">\(M_1\)</span> 模型在统计学上显著更优。</p></li>
</ol>
<p>现在我们以偏差统计量为例，详细介绍一下比较两个模型的检验过程。
首先我们设定零假设代表模型 <span class="math notranslate nohighlight">\(M_0\)</span>，模型参数是 <span class="math notranslate nohighlight">\(\beta_0\)</span>，参数数量为 <span class="math notranslate nohighlight">\(q\)</span> 。
备择假设代表模型 <span class="math notranslate nohighlight">\(M_1\)</span> ，模型参数是 <span class="math notranslate nohighlight">\(\beta_1\)</span>，参数数量为 <span class="math notranslate nohighlight">\(p\)</span> ，有 <span class="math notranslate nohighlight">\(q&lt;p\)</span> 。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-38">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-38" title="公式的永久链接">¶</a></span>\[ \begin{align}\begin{aligned}&amp;H_0: G_0=G_1 \ \text{两个模型拟合效果一样}\\&amp;H_1: G_0 != G_1 \ \text{两个模型拟合效果具有统计学上的显著差异}\end{aligned}\end{align} \]</div>
<p>我们用 <span class="math notranslate nohighlight">\(D_0\)</span> 表示模型 <span class="math notranslate nohighlight">\(M_0\)</span> 的偏差，
用符号 <span class="math notranslate nohighlight">\(D_1\)</span> 表示模型 <span class="math notranslate nohighlight">\(M_1\)</span> 的偏差，
两个模型偏差统计量的差值为</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-39">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-39" title="公式的永久链接">¶</a></span>\[ \begin{align}\begin{aligned}\Delta D &amp;= D_0 - D_1\\&amp;= 2[ \ell(b_s;y) - \ell(b_0;y) ] - 2[ \ell(b_s;y) - \ell(b_1;y) ]\\&amp;= 2[  \ell(b_1;y) - \ell(b_0;y)]\end{aligned}\end{align} \]</div>
<p>我们发现 <span class="math notranslate nohighlight">\(\Delta D\)</span> 的计算方法和 <span class="math notranslate nohighlight">\(D\)</span> 的计算方法是一致，都是两个模型对数似然值的差。
根据 <code class="xref std std-numref docutils literal notranslate"><span class="pre">ch_influence_deviance</span></code> 的理论，如果两个模型拟合效果接近，则 <span class="math notranslate nohighlight">\(\Delta D\)</span>
就渐近服从自由度为 <span class="math notranslate nohighlight">\(q-p\)</span> 中心卡方分布</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-40">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-40" title="公式的永久链接">¶</a></span>\[\Delta D \sim \chi^2(p-q)\]</div>
<p>此时 <span class="math notranslate nohighlight">\(\Delta D\)</span> 的期望值是 <span class="math notranslate nohighlight">\(p-q\)</span> 。
然而，如果两个模型拟合效果相差较大，则 <span class="math notranslate nohighlight">\(\Delta D\)</span> 渐近服从非中心卡方分布</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-41">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-41" title="公式的永久链接">¶</a></span>\[\Delta D \sim \chi^2(p-q,v)\]</div>
<p>此时 <span class="math notranslate nohighlight">\(\Delta D\)</span> 的期望值是 <span class="math notranslate nohighlight">\(p-q+v\)</span> ，将会明显大于 <span class="math notranslate nohighlight">\(p-q\)</span> ，
这个结论将用于对 <span class="math notranslate nohighlight">\(H_0\)</span> 进行显著性检验。</p>
<p>根据假设检验的过程，我们计算出 <span class="math notranslate nohighlight">\(\Delta D\)</span> 的值，然后看这个值是否落在
分布 <span class="math notranslate nohighlight">\(\chi^2(p-q)\)</span> 的拒绝域(比如是否落在图形两端 <span class="math notranslate nohighlight">\(100*\alpha \%\)</span> 的区域内)
。如果落在拒绝域内，则拒绝 <span class="math notranslate nohighlight">\(H_0\)</span> 假设，接受 <span class="math notranslate nohighlight">\(H_1\)</span> 假设。</p>
<div class="admonition important">
<p class="admonition-title">重要</p>
<p>通常如果两个模型拟合能力相差巨大，<span class="math notranslate nohighlight">\(\Delta D\)</span> 直观上就很大了，此时也没有进行假设检验的必要了。
当两个模型的拟合能力比较接近，从经验上(直观上)无法判断 <span class="math notranslate nohighlight">\(\Delta D\)</span> 是否显著时，才有假设检验的必要。
此外，相比于直接使用偏差 <span class="math notranslate nohighlight">\(D\)</span> 做检验，使用统计量 <span class="math notranslate nohighlight">\(\Delta D\)</span> 进行假设检验更好一些。
因为 <span class="math notranslate nohighlight">\(\Delta D\)</span> 通常比单独的偏差 <span class="math notranslate nohighlight">\(D\)</span> 更加接近中心卡方分布。
这是因为计算 <span class="math notranslate nohighlight">\(D\)</span> 的两个模型（饱和模型和拟合模型）的拟合能力差别更大，实际中 <span class="math notranslate nohighlight">\(D\)</span> 更接近非中心卡方分布。</p>
</div>
<p>然而要使用统计量 <span class="math notranslate nohighlight">\(\Delta D\)</span> 作为检验统计量，这就需要能计算出 <span class="math notranslate nohighlight">\(\Delta D\)</span> 的值。
前文我们讲过，部分指数族分布存在分散参数 <span class="math notranslate nohighlight">\(\phi\)</span> ，比如高斯分布，对于这些模型必须知道分散参数 <span class="math notranslate nohighlight">\(\phi\)</span>
值才能计算出真实的偏差值 <span class="math notranslate nohighlight">\(D\)</span> ，进而计算出统计量 <span class="math notranslate nohighlight">\(\Delta D\)</span> 。
虽然我们可以通过一些前提假设解决这个问题，比如传统线性回归(高斯)模型假设 <span class="math notranslate nohighlight">\(a(\phi)=\sigma^2=1\)</span>，
但这样做会增大 <span class="math notranslate nohighlight">\(D\)</span> 的计算误差，很可能导致得出错误的检验结论。
针对这个这个问题，我们可以采用另一个检验统计量，F检验统计量，又称F检验。</p>
<p>在 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 中，我们把分散参数 <span class="math notranslate nohighlight">\(\phi\)</span> 看做是冗余参数，冗余参数的意思是其不再 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 最大似然参数估计的范畴内，
在进行最大似然估计时认为其值是已知。这就需求通弄其它方法来确定冗余参数的值，一般是根据经验进行假设，也可以单独从数据中估计。
回顾下 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 模型一般形式的定义，在定义中，分散参数 <span class="math notranslate nohighlight">\(\phi\)</span> 与线性预测器 <span class="math notranslate nohighlight">\(\eta=\beta^T x\)</span> 是独立无关的，
换句话说，两个嵌套模型，拥有同样的 <span class="math notranslate nohighlight">\(\phi\)</span> ，再结合偏差和尺度化偏差的关系，可得</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-42">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-42" title="公式的永久链接">¶</a></span>\[ \begin{align}\begin{aligned}D_0 &amp;= \frac{d_0}{\phi}\\D_1 &amp;= \frac{d_1}{\phi}\\\Delta D &amp;=  D_0 - D_1 = \frac{d_0-d_1}{\phi}\end{aligned}\end{align} \]</div>
<p>现在回顾下三大抽样分布中的 <span class="math notranslate nohighlight">\(F\)</span> 分布，根据 <span class="math notranslate nohighlight">\(F\)</span> 分布的定义，以下统计量服从 <span class="math notranslate nohighlight">\(F\)</span> 分布。</p>
<div class="math notranslate nohighlight" id="equation-glm-source-influence-bak-43">
<span class="eqno">()<a class="headerlink" href="#equation-glm-source-influence-bak-43" title="公式的永久链接">¶</a></span>\[F = \left. \frac{\Delta D}{p-q} \middle/ \frac{D_1}{N-p} \right.
= \left. \frac{d_0 - d_1}{p-q} \middle/ \frac{d_1}{N-p} \right.
\sim F(p-q,N-P)\]</div>
<p><span class="math notranslate nohighlight">\(F\)</span> 检验统计量可以消除分散参数 <span class="math notranslate nohighlight">\(\phi\)</span> 的影响。
利用 <span class="math notranslate nohighlight">\(F\)</span> 统计量检验过程和 <span class="math notranslate nohighlight">\(\Delta D\)</span> 是一样的，
如果 <span class="math notranslate nohighlight">\(H_0\)</span> 成立，两个模型拟合效果接近，则 <span class="math notranslate nohighlight">\(F\)</span> 统计量渐近服从中心分布 <span class="math notranslate nohighlight">\(F(p-q,N-P)\)</span>。
计算出 <span class="math notranslate nohighlight">\(F\)</span> 的值，检验其是否落在拒绝域内。</p>
<div class="admonition important">
<p class="admonition-title">重要</p>
<p>按照 <span class="math notranslate nohighlight">\(F\)</span> 分布的定义，两个独立的 <strong>中心卡方</strong> 随机变量各自除以自由度后，再相除得到 <strong>中心</strong> <span class="math notranslate nohighlight">\(F\)</span> 分布。
一个 <strong>非中心卡方</strong> 随机变量除以一个 <strong>中心卡方</strong> 随机变量得到 <strong>非中心</strong> <span class="math notranslate nohighlight">\(F\)</span> 分布。
<strong>这里都要求第二个卡方变量必须是中心卡方变量</strong>，所以要应用 <span class="math notranslate nohighlight">\(F\)</span> 检验统计量前提是模型 <span class="math notranslate nohighlight">\(M_1\)</span> 是一个”好的”模型，
其偏差统计量 <span class="math notranslate nohighlight">\(D_1\)</span> 是一个中心卡方分布。</p>
</div>
</div>
<div class="section" id="id13">
<h3>正态性检验<a class="headerlink" href="#id13" title="永久链接至标题">¶</a></h3>
</div>
</div>
<div class="section" id="id14">
<h2>案例<a class="headerlink" href="#id14" title="永久链接至标题">¶</a></h2>
<dl class="field-list simple">
<dt class="field-odd">df_model</dt>
<dd class="field-odd"><p>模型的自由度，就是特征数量，也是协变量参数的数量 :math:<a href="#id15"><span class="problematic" id="id16">`</span></a>p-1`（不包含截距参数）</p>
</dd>
<dt class="field-even">df_resid</dt>
<dd class="field-even"><p>观测样本数量 <span class="math notranslate nohighlight">\(N\)</span> 减去协变量参数数量 :math:<a href="#id17"><span class="problematic" id="id18">`</span></a>p`（包括截距参数）。</p>
</dd>
</dl>
<div class="section" id="id19">
<h3>线性回归<a class="headerlink" href="#id19" title="永久链接至标题">¶</a></h3>
</div>
<div class="section" id="id20">
<h3>GLM<a class="headerlink" href="#id20" title="永久链接至标题">¶</a></h3>
</div>
</div>
<div class="section" id="id21">
<h2>笔记<a class="headerlink" href="#id21" title="永久链接至标题">¶</a></h2>
<p>在统计学中，我们需要通过数据的表现去证明假设的成立与否。
如果原假设是成立的，那么其一定会影响到数据的表现，也就是数据一定会受到原假设的影响。
因此最直接的方法就是，找到一个和原假设相关的数据统计量(statistic)，
通过这个统计量的值去验证原假设是否成立。</p>
<p>然而，在统计的世界中，通常我们只能得到一些采样数据，背后隐藏的”真理”是不可知的，
此时只能通过局部采样数据去”猜测”背后的”真理”。
通常我们会用一个随机变量去表示背后的”真理”，采样数据就是这个随机变量的观测样本(observations)。
样本的统计量(statistic)是随机变量样本的函数，不同的观测样本得到不同的统计量值，
因此样本统计量也是一个随机变量，
统计量的概率分布是受到样本所属概率分布的影响的。</p>
<p>我们需要根据样本统计量的值去验证原假设是否成立，
但是统计量也是一个随机变量，它的值也就是随机值，
通常只有统计量取得的某些值时才能证明原假设的成立，
取得其它值时原假设就是不成立的。
既然统计量是个随机变量，我们就需要用概率去描述它，</p>
<p>我们的样本的数据是随机变量的采样值，样本的统计量作为样本的函数也是一个随机量，</p>
<p>假设一个事件为真，作为零假设，它的相反事件</p>
<p>通常这个统计量 抽样分布 是 (近似、渐近)正态分布或者卡方分布</p>
<p>score statistic 服从卡方分布。在 <code class="docutils literal notranslate"><span class="pre">GLM</span></code> 中，标准化的 score 统计量是服从正态分布的，其平方是服从卡方分布的</p>
<p>似然估计量是服从正态分布的</p>
<p>偏差是服从卡方分布的</p>
<p>Wald statistic 统计量服从卡方分布</p>
<p><code class="docutils literal notranslate"><span class="pre">GLM</span></code> 中假设检验的方法</p>
<ol class="arabic simple">
<li><p>score statistic</p></li>
<li><p>Wald statistic</p></li>
<li><p>偏差统计量 （compare the goodness of fit of two models.）</p></li>
</ol>
<p>An example role <a href="#id22"><span class="problematic" id="id23">:tikz:`[thick] \node[blue,draw] (a) {A};
\node[draw,dotted,right of=a] {B} edge[&lt;-] (a);`</span></a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>


    <script src="https://utteranc.es/client.js"
            repo="zhangzhenhu/blog"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>



  <div role="contentinfo">
    <p>
        &#169; 版权所有 2018, zhangzhenhu(acmtiger@outlook.com) 禁止一切形式的转载！.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>.



</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>