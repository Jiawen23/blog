#######################################
网络层说明
#######################################



DenseWithSparseWeights
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

本身是一个全连接层，在此基础上增加了一个额外的小功能。
可以按照固定比例，把权重矩阵部分值设置为0.0，
由入参 ``sparsity`` 控制这个比例。


.. code-block:: python


    class DenseWithSparseWeights(tf.keras.layers.Dense):
        """
        本身是一个全连接层，在此基础上增加了一个额外的小功能。
        可以按照固定比例，把权重矩阵部分值设置为0.0，
        由入参 ``sparsity`` 控制这个比例。

        Just your regular densely-connected NN layer but with sparse weights.

        `Dense` implements the operation:
        `output = activation(dot(input, kernel) + bias)`
        where `activation` is the element-wise activation function
        passed as the `activation` argument, `kernel` is a weights matrix
        created by the layer, and `bias` is a bias vector created by the layer
        (only applicable if `use_bias` is `True`).
        It creates `kernel_mask` to set fraction of the `kernel` weights to zero.

        Note: If the input to the layer has a rank greater than 2, then
        it is flattened prior to the initial dot product with `kernel`.

        Arguments:
            sparsity: Float between 0 and 1. Fraction of the `kernel`
                weights to set to zero.
            units: Positive integer, dimensionality of the output space.
            activation: Activation function to use.
                If you don't specify anything, no activation is applied
                (ie. "linear" activation: `a(x) = x`).
            use_bias: Boolean, whether the layer uses a bias vector.
            kernel_initializer: Initializer for the `kernel` weights matrix.
            bias_initializer: Initializer for the bias vector.
            kernel_regularizer: Regularizer function applied to
                the `kernel` weights matrix.
            bias_regularizer: Regularizer function applied to the bias vector.
            activity_regularizer: Regularizer function applied to
                the output of the layer (its "activation")..
            kernel_constraint: Constraint function applied to
                the `kernel` weights matrix.
            bias_constraint: Constraint function applied to the bias vector.

        Input shape:
            N-D tensor with shape: `(batch_size, ..., input_dim)`.
            The most common situation would be
            a 2D input with shape `(batch_size, input_dim)`.

        Output shape:
            N-D tensor with shape: `(batch_size, ..., units)`.
            For instance, for a 2D input with shape `(batch_size, input_dim)`,
            the output would have shape `(batch_size, units)`.
        """

        def __init__(self, sparsity: float = 0.8, **kwargs: Any) -> None:
            super().__init__(**kwargs)
            self.sparsity = sparsity

        def build(self, input_shape: tf.TensorShape) -> None:
            super().build(input_shape)
            # create random mask to set fraction of the `kernel` weights to zero
            # 按照均匀分布生成 0~1 之间的随机值
            kernel_mask = tf.random.uniform(tf.shape(self.kernel), 0, 1)

            # bool 矩阵强制转换成 self.kernel.dtype 类型
            # True -> 1.0
            # False -> 0.0
            kernel_mask = tf.cast(
                # 返回一个bool矩阵：
                # 大于等于 self.sparsity 的位置是 True，反之是 False
                tf.greater_equal(kernel_mask, self.sparsity), self.kernel.dtype
            )
            # kernel_mask 转换成一个张量变量，注意：trainable=False 表示它的常量值
            self.kernel_mask = tf.Variable(
                initial_value=kernel_mask, trainable=False, name="kernel_mask"
            )

        def call(self, inputs: tf.Tensor) -> tf.Tensor:
            # set fraction of the `kernel` weights to zero according to precomputed mask
            # 把权重 self.kernel 中部分位置设置为 0.0
            self.kernel.assign(self.kernel * self.kernel_mask)
            return super().call(inputs)


DenseForSparse
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
普通的全连接层，只不过它的输入是稀疏矩阵 `tf.SparseTensor`




Ffnn
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

前向网络层，包括2层全连接成(DenseWithSparseWeights)和1层Dropout



InputMask
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
The layer that masks 15% of the input

遮挡 15%


DotProductLoss
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


